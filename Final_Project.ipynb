{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4f174cb-36b1-42f2-9460-337ad95d0d01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Loads employee dimension data into a Delta table.\n",
    "# \"At least 3 additional dimension tables\" \n",
    "# Use files from a cloud-based file system (DBFS) as a source.\n",
    "# Load employee dimension data from a CSV stored in DBFS\n",
    "df_dim_employees = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_DimEmployees.csv\")\n",
    "\n",
    "df_dim_employees.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.dim_employees\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e254f610-0bd2-44c5-a012-4058dd93804c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------------+----------+--------------------+--------------------+--------------+-------------+-------------+--------------+--------+--------------+---------------+--------------+--------------------+\n|employee_key|          company|     last_name|first_name|       email_address|           job_title|business_phone|   home_phone|   fax_number|       address|    city|state_province|zip_postal_code|country_region|            web_page|\n+------------+-----------------+--------------+----------+--------------------+--------------------+--------------+-------------+-------------+--------------+--------+--------------+---------------+--------------+--------------------+\n|           1|Northwind Traders|     Freehafer|     Nancy|nancy@northwindtr...|Sales Representative| (123)555-0100|(123)555-0102|(123)555-0103|123 1st Avenue| Seattle|            WA|          99999|           USA|#http://northwind...|\n|           2|Northwind Traders|       Cencini|    Andrew|andrew@northwindt...|Vice President, S...| (123)555-0100|(123)555-0102|(123)555-0103|123 2nd Avenue|Bellevue|            WA|          99999|           USA|http://northwindt...|\n|           3|Northwind Traders|         Kotas|       Jan|jan@northwindtrad...|Sales Representative| (123)555-0100|(123)555-0102|(123)555-0103|123 3rd Avenue| Redmond|            WA|          99999|           USA|http://northwindt...|\n|           4|Northwind Traders|     Sergienko|    Mariya|mariya@northwindt...|Sales Representative| (123)555-0100|(123)555-0102|(123)555-0103|123 4th Avenue|Kirkland|            WA|          99999|           USA|http://northwindt...|\n|           5|Northwind Traders|        Thorpe|    Steven|steven@northwindt...|       Sales Manager| (123)555-0100|(123)555-0102|(123)555-0103|123 5th Avenue| Seattle|            WA|          99999|           USA|http://northwindt...|\n|           6|Northwind Traders|       Neipper|   Michael|michael@northwind...|Sales Representative| (123)555-0100|(123)555-0102|(123)555-0103|123 6th Avenue| Redmond|            WA|          99999|           USA|http://northwindt...|\n|           7|Northwind Traders|          Zare|    Robert|robert@northwindt...|Sales Representative| (123)555-0100|(123)555-0102|(123)555-0103|123 7th Avenue| Seattle|            WA|          99999|           USA|http://northwindt...|\n|           8|Northwind Traders|      Giussani|     Laura|laura@northwindtr...|   Sales Coordinator| (123)555-0100|(123)555-0102|(123)555-0103|123 8th Avenue| Redmond|            WA|          99999|           USA|http://northwindt...|\n|           9|Northwind Traders|Hellung-Larsen|      Anne|anne@northwindtra...|Sales Representative| (123)555-0100|(123)555-0102|(123)555-0103|123 9th Avenue| Seattle|            WA|          99999|           USA|http://northwindt...|\n+------------+-----------------+--------------+----------+--------------------+--------------------+--------------+-------------+-------------+--------------+--------+--------------+---------------+--------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# View the loaded employee dimension table to confirm contents\n",
    "spark.sql(\"SELECT * FROM default.dim_employees\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77f837b3-32b0-477b-b1fa-9a8ed9c0d7d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n|department_id|department_name|\n+-------------+---------------+\n|            1|             HR|\n|            2|    Engineering|\n|            3|          Sales|\n+-------------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create a Department dimension \n",
    "# \"At least 3 additional dimension tables\"\n",
    "from pyspark.sql import Row\n",
    "departments = [\n",
    "    Row(department_id=1, department_name=\"HR\"),\n",
    "    Row(department_id=2, department_name=\"Engineering\"),\n",
    "    Row(department_id=3, department_name=\"Sales\")\n",
    "]\n",
    "df_dim_departments = spark.createDataFrame(departments)\n",
    "df_dim_departments.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ae01f1-4c9a-4ccf-8ff6-53a5c12a36e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Saves the Department dimension to Delta format and populates the Lakehouse architecture with structured dimension tables\n",
    "df_dim_departments.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.dim_departments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f62e2962-9e0b-41a5-9aca-7b122faba715",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-------------+------+\n|sale_id|employee_id|department_id|amount|\n+-------+-----------+-------------+------+\n|   1001|          1|            1| 500.0|\n|   1002|          2|            2|1200.0|\n|   1003|          3|            3| 300.0|\n+-------+-----------+-------------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create a Fact Sales table (simulated transactional data) to meet the \"At least 1 fact table that models the business process\" requirement - Important for OLAP systems for tracking measurable events\n",
    "\n",
    "from pyspark.sql import Row\n",
    "sales = [\n",
    "    Row(sale_id=1001, employee_id=1, department_id=1, amount=500.0),\n",
    "    Row(sale_id=1002, employee_id=2, department_id=2, amount=1200.0),\n",
    "    Row(sale_id=1003, employee_id=3, department_id=3, amount=300.0)\n",
    "]\n",
    "df_fact_sales = spark.createDataFrame(sales)\n",
    "df_fact_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58d01605-64bf-4bba-a2f5-64f2dbeaa9fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save fact_sales to Delta fact table\n",
    "\n",
    "df_fact_sales.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.fact_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60910e2b-d0fa-403b-8688-e2a974338314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ingest purchase order fact from JSON into Bronze layer\n",
    "\n",
    "df_fact_purchase_orders = spark.read.option(\"multiline\", \"true\") \\\n",
    "    .json(\"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_Fact_PurchaseOrders01.json\")\n",
    "df_fact_purchase_orders.write.format(\"delta\").mode(\"overwrite\").save(\"dbfs:/Volumes/workspace/default/northwind_schema/bronze/Northwind_Fact_PurchaseOrders01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f67c4db9-66e6-45bb-9c77-8a5b1173bafe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# \"At least 3 additional dimension tables\"\n",
    "# Defines product dimension table (Dimensional Table 3)\n",
    "\n",
    "df_dim_products = spark.createDataFrame([\n",
    "    Row(product_id=1001, product_name=\"Laptop\", price=1000.0),\n",
    "    Row(product_id=1002, product_name=\"Mouse\", price=25.0),\n",
    "    Row(product_id=1003, product_name=\"Keyboard\", price=45.0)\n",
    "])\n",
    "df_dim_products.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.dim_products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afec1274-8728-40a7-a1cf-0f6fd4c3ea13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Defines customer dimension table (Dimensional Table 4)\n",
    "\n",
    "from pyspark.sql import Row\n",
    "df_dim_customers = spark.createDataFrame([\n",
    "    Row(customer_id=101, name=\"John Doe\", region=\"East\"),\n",
    "    Row(customer_id=102, name=\"Jane Smith\", region=\"West\"),\n",
    "    Row(customer_id=103, name=\"Carlos Rivera\", region=\"South\")\n",
    "])\n",
    "df_dim_customers.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.dim_customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc4bdcd-0cf9-4f08-b037-8fe650f3116c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+-----+----+---------+----------+----+-------+\n|      date|day|month|year| day_name|month_name|week|quarter|\n+----------+---+-----+----+---------+----------+----+-------+\n|2023-01-01|  1|    1|2023|   Sunday|   January|  52|      1|\n|2023-01-02|  2|    1|2023|   Monday|   January|   1|      1|\n|2023-01-03|  3|    1|2023|  Tuesday|   January|   1|      1|\n|2023-01-04|  4|    1|2023|Wednesday|   January|   1|      1|\n|2023-01-05|  5|    1|2023| Thursday|   January|   1|      1|\n+----------+---+-----+----+---------+----------+----+-------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Generate a Date Dimension with derived fields for project requirement \n",
    "\n",
    "from pyspark.sql.functions import col, to_date, monotonically_increasing_id\n",
    "from pyspark.sql import functions as F\n",
    "date_range = spark.range(0, 365).withColumn(\"date\", F.expr(\"date_add('2023-01-01', cast(id as int))\"))\n",
    "df_dim_date = date_range.select(\n",
    "    col(\"date\").alias(\"date\"),\n",
    "    F.dayofmonth(\"date\").alias(\"day\"),\n",
    "    F.month(\"date\").alias(\"month\"),\n",
    "    F.year(\"date\").alias(\"year\"),\n",
    "    F.date_format(\"date\", \"EEEE\").alias(\"day_name\"),\n",
    "    F.date_format(\"date\", \"MMMM\").alias(\"month_name\"),\n",
    "    F.weekofyear(\"date\").alias(\"week\"),\n",
    "    F.quarter(\"date\").alias(\"quarter\")\n",
    ")\n",
    "df_dim_date.show(5)\n",
    "df_dim_date.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.dim_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecdf72b7-338e-4147-9a02-a048414fe89e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS default.fact_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ab9c9bd-703e-4079-a6ee-fcbf7216635f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_fact_sales.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.fact_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05dc1447-cc71-4798-8809-3cef95db53bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------+----------+----------+--------+----------+------------+\n|sale_id|employee_id|customer_id|product_id|      date|quantity|unit_price|total_amount|\n+-------+-----------+-----------+----------+----------+--------+----------+------------+\n|      1|          1|        101|      1001|2023-01-01|       2|      10.0|        20.0|\n|      2|          2|        102|      1002|2023-01-02|       1|      20.0|        20.0|\n|      3|          3|        103|      1003|2023-01-03|       5|       5.0|        25.0|\n+-------+-----------+-----------+----------+----------+--------+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create and load the fact_sales table to model the core business process (sales transactions)\n",
    "# Fact table requirement \n",
    "# Adds a derived column (`total_amount`) as part of the Transform step in ETL\n",
    "# Uses in-memory data (simulating a streaming or transactional source)\n",
    "# Saves result to Delta Lake as part of the Bronze/Silver pipeline\n",
    "from pyspark.sql import Row\n",
    "sales_data = [\n",
    "    Row(sale_id=1, employee_id=1, customer_id=101, product_id=1001, date=\"2023-01-01\", quantity=2, unit_price=10.0),\n",
    "    Row(sale_id=2, employee_id=2, customer_id=102, product_id=1002, date=\"2023-01-02\", quantity=1, unit_price=20.0),\n",
    "    Row(sale_id=3, employee_id=3, customer_id=103, product_id=1003, date=\"2023-01-03\", quantity=5, unit_price=5.0)\n",
    "]\n",
    "df_fact_sales = spark.createDataFrame(sales_data)\n",
    "df_fact_sales = df_fact_sales.withColumn(\"date\", to_date(\"date\"))\n",
    "df_fact_sales = df_fact_sales.withColumn(\"total_amount\", col(\"quantity\") * col(\"unit_price\"))\n",
    "df_fact_sales.show()\n",
    "df_fact_sales.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.fact_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "524f4199-50f4-433c-b0d4-56b4cae6ceaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Silver Layer: Clean and sales data by joining with dimension tables\n",
    "\n",
    "df_silver_sales = df_fact_sales \\\n",
    "    .join(df_dim_employees, df_fact_sales[\"employee_id\"] == df_dim_employees[\"employee_key\"]) \\\n",
    "    .join(df_dim_customers, \"customer_id\") \\\n",
    "    .join(df_dim_products, \"product_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "190d338b-7da2-40b6-9e95-e47ed35e7311",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_silver_sales = df_silver_sales.drop(\"employee_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32fd5135-6d9d-486f-b40b-3ad5b63229e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "# Uses 'name' for customers, and concatenates first/last name for employees\n",
    "df_silver_sales_clean = df_silver_sales.select(\n",
    "    \"sale_id\",\n",
    "    \"employee_id\", concat_ws(\" \", df_dim_employees[\"first_name\"], df_dim_employees[\"last_name\"]).alias(\"employee_name\"),\n",
    "    \"customer_id\", df_dim_customers[\"name\"].alias(\"customer_name\"),\n",
    "    \"product_id\", \"product_name\",\n",
    "    \"date\", \"quantity\", \"unit_price\", \"total_amount\"\n",
    ")\n",
    "\n",
    "# Saves Silver table\n",
    "spark.sql(\"DROP TABLE IF EXISTS default.silver_sales\")\n",
    "df_silver_sales_clean.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.silver_sales\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "221f4856-41cc-4e22-ae32-a69f8966a28b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-------------------+-------------+\n|  employee_name|product_name|total_quantity_sold|total_revenue|\n+---------------+------------+-------------------+-------------+\n|      Jan Kotas|    Keyboard|                  5|         25.0|\n| Andrew Cencini|       Mouse|                  1|         20.0|\n|Nancy Freehafer|      Laptop|                  2|         20.0|\n+---------------+------------+-------------------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Gold Layer: Summarize metrics for business insight (OLAP)\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "df_silver_sales = spark.table(\"default.silver_sales\")\n",
    "df_gold_sales_summary = df_silver_sales.groupBy(\"employee_name\", \"product_name\") \\\n",
    "    .agg(\n",
    "        sum(\"quantity\").alias(\"total_quantity_sold\"),\n",
    "        sum(\"total_amount\").alias(\"total_revenue\")\n",
    "    )\n",
    "spark.sql(\"DROP TABLE IF EXISTS default.gold_sales_summary\")\n",
    "df_gold_sales_summary.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.gold_sales_summary\")\n",
    "df_gold_sales_summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4188da2f-4a67-453d-be34-ea2cb8d62ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- approved_by: long (nullable = true)\n |-- approved_date_key: long (nullable = true)\n |-- created_by: long (nullable = true)\n |-- creation_date_key: long (nullable = true)\n |-- fact_purchase_order_key: long (nullable = true)\n |-- inventory_key: long (nullable = true)\n |-- payment_amount: long (nullable = true)\n |-- payment_date: string (nullable = true)\n |-- po_detail_date_received_key: long (nullable = true)\n |-- po_detail_posted_to_inventory: long (nullable = true)\n |-- po_detail_quantity: long (nullable = true)\n |-- po_detail_unit_cost: long (nullable = true)\n |-- product_key: long (nullable = true)\n |-- purchase_order_key: long (nullable = true)\n |-- purchase_order_status: string (nullable = true)\n |-- shipping_fee: long (nullable = true)\n |-- submitted_by: long (nullable = true)\n |-- submitted_date_key: long (nullable = true)\n |-- supplier_key: long (nullable = true)\n |-- taxes: long (nullable = true)\n\n+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|approved_by|approved_date_key|created_by|creation_date_key|fact_purchase_order_key|inventory_key|payment_amount|payment_date|po_detail_date_received_key|po_detail_posted_to_inventory|po_detail_quantity|po_detail_unit_cost|product_key|purchase_order_key|purchase_order_status|shipping_fee|submitted_by|submitted_date_key|supplier_key|taxes|\n+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|2          |20060122         |2         |20060122         |1                      |59           |0             |NULL        |20060122                   |1                            |40                |14                 |1          |90                |Approved             |0           |2           |20060114          |1           |0    |\n|2          |20060122         |2         |20060122         |2                      |60           |0             |NULL        |20060122                   |1                            |60                |10                 |34         |90                |Approved             |0           |2           |20060114          |1           |0    |\n|2          |20060122         |2         |20060122         |3                      |61           |0             |NULL        |20060122                   |1                            |100               |34                 |43         |90                |Approved             |0           |2           |20060114          |1           |0    |\n|2          |20060122         |2         |20060122         |4                      |62           |0             |NULL        |20060122                   |1                            |125               |2                  |81         |90                |Approved             |0           |2           |20060114          |1           |0    |\n|2          |20060122         |2         |20060122         |5                      |NULL         |0             |NULL        |NULL                       |0                            |40                |14                 |1          |90                |Approved             |0           |2           |20060114          |1           |0    |\n+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_flat = spark.read.option(\"multiline\", \"true\").json(\n",
    "    \"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_Fact_PurchaseOrders01.json\"\n",
    ")\n",
    "\n",
    "df_flat.printSchema()\n",
    "df_flat.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d3db28e-a267-432a-90c3-58f855f902f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_flat.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(\"dbfs:/Volumes/workspace/default/northwind_schema/bronze_purchase_orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81918458-5ab4-4a9c-ad47-7576098a5ec3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- PurchaseOrderID: integer (nullable = true)\n |-- EmployeeID: integer (nullable = true)\n |-- VendorID: integer (nullable = true)\n |-- OrderDate: date (nullable = true)\n |-- TotalDue: double (nullable = true)\n |-- approved_by: long (nullable = true)\n |-- approved_date_key: long (nullable = true)\n |-- created_by: long (nullable = true)\n |-- creation_date_key: long (nullable = true)\n |-- fact_purchase_order_key: long (nullable = true)\n |-- inventory_key: long (nullable = true)\n |-- payment_amount: long (nullable = true)\n |-- payment_date: string (nullable = true)\n |-- po_detail_date_received_key: long (nullable = true)\n |-- po_detail_posted_to_inventory: long (nullable = true)\n |-- po_detail_quantity: long (nullable = true)\n |-- po_detail_unit_cost: long (nullable = true)\n |-- product_key: long (nullable = true)\n |-- purchase_order_key: long (nullable = true)\n |-- purchase_order_status: string (nullable = true)\n |-- shipping_fee: long (nullable = true)\n |-- submitted_by: long (nullable = true)\n |-- submitted_date_key: long (nullable = true)\n |-- supplier_key: long (nullable = true)\n |-- taxes: long (nullable = true)\n\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|PurchaseOrderID|EmployeeID|VendorID|OrderDate|TotalDue|approved_by|approved_date_key|created_by|creation_date_key|fact_purchase_order_key|inventory_key|payment_amount|payment_date|po_detail_date_received_key|po_detail_posted_to_inventory|po_detail_quantity|po_detail_unit_cost|product_key|purchase_order_key|purchase_order_status|shipping_fee|submitted_by|submitted_date_key|supplier_key|taxes|\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|NULL           |NULL      |NULL    |NULL     |NULL    |2          |20060122         |2         |20060122         |1                      |59           |0             |NULL        |20060122                   |1                            |40                |14                 |1          |90                |Approved             |0           |2           |20060114          |1           |0    |\n|NULL           |NULL      |NULL    |NULL     |NULL    |2          |20060122         |2         |20060122         |2                      |60           |0             |NULL        |20060122                   |1                            |60                |10                 |34         |90                |Approved             |0           |2           |20060114          |1           |0    |\n|NULL           |NULL      |NULL    |NULL     |NULL    |2          |20060122         |2         |20060122         |3                      |61           |0             |NULL        |20060122                   |1                            |100               |34                 |43         |90                |Approved             |0           |2           |20060114          |1           |0    |\n|NULL           |NULL      |NULL    |NULL     |NULL    |2          |20060122         |2         |20060122         |4                      |62           |0             |NULL        |20060122                   |1                            |125               |2                  |81         |90                |Approved             |0           |2           |20060114          |1           |0    |\n|NULL           |NULL      |NULL    |NULL     |NULL    |2          |20060122         |2         |20060122         |5                      |NULL         |0             |NULL        |NULL                       |0                            |40                |14                 |1          |90                |Approved             |0           |2           |20060114          |1           |0    |\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Reads the Bronze Layer to start Silver transformation (ETL - Extract phase)\n",
    "\n",
    "bronze = spark.read.format(\"delta\").load(\"dbfs:/Volumes/workspace/default/northwind_schema/bronze_purchase_orders\")\n",
    "bronze.printSchema()\n",
    "bronze.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a26145-23ae-4f3d-a7ea-a0dedbea31ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|PurchaseOrderID|EmployeeID|VendorID|OrderDate|TotalDue|approved_by|approved_date_key|created_by|creation_date_key|fact_purchase_order_key|inventory_key|payment_amount|payment_date|po_detail_date_received_key|po_detail_posted_to_inventory|po_detail_quantity|po_detail_unit_cost|product_key|purchase_order_key|purchase_order_status|shipping_fee|submitted_by|submitted_date_key|supplier_key|taxes|\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      1|           59|             0|        NULL|                   20060122|                            1|                40|                 14|          1|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      2|           60|             0|        NULL|                   20060122|                            1|                60|                 10|         34|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      3|           61|             0|        NULL|                   20060122|                            1|               100|                 34|         43|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      4|           62|             0|        NULL|                   20060122|                            1|               125|                  2|         81|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      5|         NULL|             0|        NULL|                       NULL|                            0|                40|                 14|          1|                90|             Approved|           0|           2|          20060114|           1|    0|\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_flat = spark.read.option(\"multiline\", \"true\").json(\n",
    "    \"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_Fact_PurchaseOrders01.json\"\n",
    ")\n",
    "\n",
    "df_flat.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .save(\"dbfs:/Volumes/workspace/default/northwind_schema/bronze_purchase_orders\")\n",
    "\n",
    "bronze = spark.read.format(\"delta\").load(\"dbfs:/Volumes/workspace/default/northwind_schema/bronze_purchase_orders\")\n",
    "bronze.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "708b31ab-f4e0-4071-be3f-9d2769d2be57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- PurchaseOrderID: integer (nullable = true)\n |-- EmployeeID: integer (nullable = true)\n |-- VendorID: integer (nullable = true)\n |-- OrderDate: date (nullable = true)\n |-- TotalDue: double (nullable = true)\n |-- approved_by: long (nullable = true)\n |-- approved_date_key: long (nullable = true)\n |-- created_by: long (nullable = true)\n |-- creation_date_key: long (nullable = true)\n |-- fact_purchase_order_key: long (nullable = true)\n |-- inventory_key: long (nullable = true)\n |-- payment_amount: long (nullable = true)\n |-- payment_date: string (nullable = true)\n |-- po_detail_date_received_key: long (nullable = true)\n |-- po_detail_posted_to_inventory: long (nullable = true)\n |-- po_detail_quantity: long (nullable = true)\n |-- po_detail_unit_cost: long (nullable = true)\n |-- product_key: long (nullable = true)\n |-- purchase_order_key: long (nullable = true)\n |-- purchase_order_status: string (nullable = true)\n |-- shipping_fee: long (nullable = true)\n |-- submitted_by: long (nullable = true)\n |-- submitted_date_key: long (nullable = true)\n |-- supplier_key: long (nullable = true)\n |-- taxes: long (nullable = true)\n\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|PurchaseOrderID|EmployeeID|VendorID|OrderDate|TotalDue|approved_by|approved_date_key|created_by|creation_date_key|fact_purchase_order_key|inventory_key|payment_amount|payment_date|po_detail_date_received_key|po_detail_posted_to_inventory|po_detail_quantity|po_detail_unit_cost|product_key|purchase_order_key|purchase_order_status|shipping_fee|submitted_by|submitted_date_key|supplier_key|taxes|\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      1|           59|             0|        NULL|                   20060122|                            1|                40|                 14|          1|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      2|           60|             0|        NULL|                   20060122|                            1|                60|                 10|         34|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      3|           61|             0|        NULL|                   20060122|                            1|               100|                 34|         43|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      4|           62|             0|        NULL|                   20060122|                            1|               125|                  2|         81|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      5|         NULL|             0|        NULL|                       NULL|                            0|                40|                 14|          1|                90|             Approved|           0|           2|          20060114|           1|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      6|           54|             0|        NULL|                   20060122|                            1|               100|                  8|          3|                91|             Approved|           0|           2|          20060114|           3|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      7|           55|             0|        NULL|                   20060122|                            1|                40|                 16|          4|                91|             Approved|           0|           2|          20060114|           3|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      8|           56|             0|        NULL|                   20060122|                            1|                40|                 16|          5|                91|             Approved|           0|           2|          20060114|           3|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                      9|           57|             0|        NULL|                   20060122|                            1|                40|                 16|         65|                91|             Approved|           0|           2|          20060114|           3|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     10|           58|             0|        NULL|                   20060122|                            1|                80|                 13|         66|                91|             Approved|           0|           2|          20060114|           3|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     11|         NULL|             0|        NULL|                       NULL|                            0|                50|                  8|          3|                91|             Approved|           0|           2|          20060114|           3|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     12|         NULL|             0|        NULL|                       NULL|                            0|                40|                 16|          4|                91|             Approved|           0|           2|          20060114|           3|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     13|           40|             0|        NULL|                   20060122|                            1|               100|                 19|          6|                92|             Approved|           0|           2|          20060114|           2|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     14|           41|             0|        NULL|                   20060122|                            1|                40|                 22|          7|                92|             Approved|           0|           2|          20060114|           2|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     15|           42|             0|        NULL|                   20060122|                            1|                40|                 30|          8|                92|             Approved|           0|           2|          20060114|           2|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     16|           43|             0|        NULL|                   20060122|                            1|                40|                 17|         14|                92|             Approved|           0|           2|          20060114|           2|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     17|           44|             0|        NULL|                   20060122|                            1|                40|                 29|         17|                92|             Approved|           0|           2|          20060114|           2|    0|\n|           NULL|      NULL|    NULL|     NULL|    NULL|          2|         20060122|         2|         20060122|                     18|           45|             0|        NULL|                   20060122|                            1|                20|                  7|         19|                92|             Approved|           0|           2|          20060114|           2|    0|\n+---------------+----------+--------+---------+--------+-----------+-----------------+----------+-----------------+-----------------------+-------------+--------------+------------+---------------------------+-----------------------------+------------------+-------------------+-----------+------------------+---------------------+------------+------------+------------------+------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Silver Layer: Loads Bronze data for further transformation and integration with dimension tables\n",
    "\n",
    "df_silver = spark.read.format(\"delta\").load(\"dbfs:/Volumes/workspace/default/northwind_schema/bronze_purchase_orders\")\n",
    "df_silver.printSchema()\n",
    "df_silver.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d9ca69c-57e5-4e1a-8b9a-f2ee2578c933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_json_array = spark.read.option(\"multiline\", \"true\").json(\"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_Fact_PurchaseOrders01.json\")\n",
    "df_flat = df_json_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c517601-5c68-49db-ab73-4153ae10b7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Saves Bronze Layer as a Delta table for SQL queries (ETL - Load step completion)\n",
    "df_flat.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.bronze_purchase_orders\")\n",
    "\n",
    "df_flat.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.bronze_purchase_orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f5dce78-6c44-4522-b9bb-ac0d12d1c41e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n|supplier_key|company   |\n+------------+----------+\n|1           |Supplier A|\n|1           |Supplier A|\n|1           |Supplier A|\n|1           |Supplier A|\n|1           |Supplier A|\n|3           |Supplier C|\n|3           |Supplier C|\n|3           |Supplier C|\n|3           |Supplier C|\n|3           |Supplier C|\n+------------+----------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Silver Layer: Joins raw purchase orders and supplier dimension table (ETL - Transform phase). To meet the join static reference data with fact table at Silver stage requirement\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "suppliers = spark.table(\"default.dim_suppliers\").alias(\"suppliers\")\n",
    "\n",
    "df_silver_purchase = bronze.alias(\"bronze\").join(\n",
    "    suppliers,\n",
    "    col(\"bronze.supplier_key\") == col(\"suppliers.supplier_key\"),\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "df_silver_purchase = df_silver_purchase.drop(col(\"suppliers.supplier_key\"))\n",
    "\n",
    "df_silver_purchase.createOrReplaceTempView(\"silver_purchase_temp\")\n",
    "\n",
    "df_silver_purchase.select(\"supplier_key\", \"company\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d2677ca-f8c8-43d2-9d09-528283a1f864",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save cleaned Silver table without duplicating keys\n",
    "\n",
    "df_silver_purchase_clean = df_silver_purchase.drop(\"supplier_key\")\n",
    "df_silver_purchase_clean.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.silver_purchase_orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e23505c-06cf-48da-aef8-2f32224e25ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Needed import\n",
    "from pyspark.sql.functions import expr, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4aa7e15-180d-464e-9441-41641d42a524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load invoices from JSON file and saves to Delta table\n",
    "df_invoices = spark.read.option(\"multiline\", \"true\") \\\n",
    "    .json(\"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_DimInvoices.json\")\n",
    "\n",
    "# Write the Delta table\n",
    "df_invoices.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"default.dim_invoices\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1e3e43f-4ac5-4781-9d4f-e204831c7bad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_orders = spark.table(\"default.silver_orders\").alias(\"orders\")\n",
    "df_invoices = spark.table(\"default.dim_invoices\").alias(\"invoices\")\n",
    "\n",
    "# Join orders and invoice data\n",
    "df_order_enriched = df_orders.join(\n",
    "    df_invoices,\n",
    "    col(\"orders.order_key\") == col(\"invoices.order_key\"),\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "df_order_enriched = df_order_enriched.drop(df_invoices[\"order_key\"])\n",
    "\n",
    "# Saves enriched data\n",
    "df_order_enriched.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.silver_orders_with_invoices\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58512fd5-0aad-4c05-88b6-9a26da128979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+\n|customer_key|total_amount_due|\n+------------+----------------+\n|8           |0               |\n|11          |0               |\n|1           |0               |\n|10          |0               |\n|7           |NULL            |\n|3           |0               |\n|4           |0               |\n|28          |0               |\n|9           |0               |\n|26          |0               |\n|29          |0               |\n|6           |0               |\n|25          |0               |\n+------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Gold Layer: Aggregate total amount due per customer to meet the demonstrate business value through summarization requirement\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df_gold_customer_summary = df_order_enriched.groupBy(\"customer_key\") \\\n",
    "    .agg(sum(\"amount_due\").alias(\"total_amount_due\"))\n",
    "\n",
    "df_gold_customer_summary.show(truncate=False)\n",
    "\n",
    "df_gold_customer_summary.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.gold_order_customer_summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ba7832b-2da7-4433-80f3-66dc8ed2f4bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------------+----------+\n|company   |total_quantity_purchased|total_cost|\n+----------+------------------------+----------+\n|Supplier C|390                     |4800      |\n|Supplier A|365                     |5370      |\n|Supplier B|280                     |5960      |\n+----------+------------------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Gold Layer: Aggregate quantities and costs by supplier to meet the demonstrate business value and vendor comparison requirement \n",
    "\n",
    "from pyspark.sql.functions import sum, expr\n",
    "\n",
    "df_gold_supplier_summary = df_silver_purchase.groupBy(\"company\").agg(\n",
    "    sum(\"po_detail_quantity\").alias(\"total_quantity_purchased\"),\n",
    "    sum(expr(\"po_detail_quantity * po_detail_unit_cost\")).alias(\"total_cost\")\n",
    ")\n",
    "\n",
    "df_gold_supplier_summary.show(truncate=False)\n",
    "\n",
    "df_gold_supplier_summary.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.gold_supplier_summary\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fc4cf4-fe84-4950-9ce0-0bd0e477baf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n|supplier_key|\n+------------+\n|           2|\n|           1|\n|           3|\n+------------+\n\n+------------+----------+\n|supplier_key|   company|\n+------------+----------+\n|           7|Supplier G|\n|           3|Supplier C|\n|           1|Supplier A|\n|           2|Supplier B|\n|           4|Supplier D|\n|           6|Supplier F|\n|          10|Supplier J|\n|           9|Supplier I|\n|           8|Supplier H|\n|           5|Supplier E|\n+------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Checks distinct keys in bronze data\n",
    "bronze.select(\"supplier_key\").distinct().show()\n",
    "\n",
    "# Checks distinct keys in suppliers dim table\n",
    "spark.table(\"default.dim_suppliers\").select(\"supplier_key\", \"company\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13e4cf98-4499-4bb3-b0be-b4f828722e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-------------------+--------+\n|company   |po_detail_quantity|po_detail_unit_cost|TotalDue|\n+----------+------------------+-------------------+--------+\n|Supplier A|40                |14                 |NULL    |\n|Supplier A|60                |10                 |NULL    |\n|Supplier A|100               |34                 |NULL    |\n|Supplier A|125               |2                  |NULL    |\n|Supplier A|40                |14                 |NULL    |\n+----------+------------------+-------------------+--------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Inspects key columns in Silver to verify data before Gold summarization\n",
    "\n",
    "df_silver_purchase_clean.select(\"company\", \"po_detail_quantity\", \"po_detail_unit_cost\", \"TotalDue\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c09f470-54d4-4263-8059-703cf7e777bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Loads each FactOrders file\n",
    "orders_2 = spark.read.option(\"multiline\", \"true\").json(\"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_FactOrders02.json\")\n",
    "orders_3 = spark.read.option(\"multiline\", \"true\").json(\"dbfs:/Volumes/workspace/default/northwind_schema/Northwind_FactOrders03.json\")\n",
    "\n",
    "# Combines to one dataframee\n",
    "df_orders = orders_2.unionByName(orders_3)\n",
    "\n",
    "# Saves Silver Delta table\n",
    "df_orders.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"default.silver_orders\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6efa5edf-fb10-4691-9c21-97e7cc936e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-------------------+----------+\n|order_key|order_date_key|invoice_date       |amount_due|\n+---------+--------------+-------------------+----------+\n|73       |20060605      |2006-04-04 11:38:32|0         |\n|72       |20060607      |2006-04-04 11:38:53|0         |\n|71       |20060524      |2006-04-04 11:39:29|0         |\n|70       |20060524      |2006-04-04 11:39:53|0         |\n|69       |20060524      |2006-04-04 11:40:16|0         |\n+---------+--------------+-------------------+----------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Check join results for orders and invoices for Gold Layer\n",
    "df_order_enriched.select(\n",
    "    \"order_key\",\n",
    "    \"order_date_key\",   \n",
    "    \"invoice_date\",\n",
    "    \"amount_due\"\n",
    ").show(5, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Final_Project_Cleaned",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}